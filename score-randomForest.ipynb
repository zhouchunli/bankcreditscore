{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier \n",
    "from sklearn import model_selection  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('df_training.csv')\n",
    "test_data = pd.read_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TLSum TLMaxSum 这两个值差异化比较大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data[train_data.TLSum < 90000]\n",
    "#train_data = train_data[train_data.TLMaxSum<120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.dropna()\n",
    "train_data = train_data.fillna(train_data.median())\n",
    "test_data = test_data.fillna(test_data.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.iloc[:,1:-1]\n",
    "y = train_data.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state=1)\n",
    "\n",
    "# 训练样本归一化\n",
    "std_x = MinMaxScaler()\n",
    "x_train = std_x.fit_transform(x_train)\n",
    "x_test = std_x.transform(x_test)\n",
    "\n",
    "# 测试样本归一化\n",
    "std_y  = MinMaxScaler()\n",
    "y_train = std_y.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test = std_y.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "# 所有训练样本的归一化\n",
    "std_x_all = MinMaxScaler()\n",
    "x_train_all = std_x_all.fit_transform(X)\n",
    "\n",
    "std_y_all = MinMaxScaler()\n",
    "y_train_all = std_y_all.fit_transform(y.values.reshape(-1,1))\n",
    "\n",
    "# 预测值处理\n",
    "std_x_test = MinMaxScaler()\n",
    "x_test_data = std_x_test.fit_transform(test_data.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10, 'min_samples_split': 81}, 0.4343291959941716)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'n_estimators':list(range(132,133,1))}\n",
    "param_test2 = {'max_depth':list(range(9,13,1)), 'min_samples_split':list(range(78,82,1))}\n",
    "param_test3 = { 'min_samples_leaf':range(18,24,2)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(n_estimators=132,max_depth=11,min_samples_split=80,min_samples_leaf=20,\n",
    "                                                           class_weight={0: 1, 1: 5},max_features='sqrt',oob_score=True ,random_state=10), \n",
    "                       param_grid = param_test2, scoring='f1',cv=5)\n",
    "gsearch1.fit(x_train_all,y_train_all)\n",
    "\n",
    "#scores = model_selection.cross_val_score(gsearch1, x_train_all, y_train_all, cv=5, scoring='f1')\n",
    "#print(\"f1: %0.2f [%s]\" % (scores.mean(), '得分'))\n",
    "gsearch1.best_params_, gsearch1.best_score_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566666666666666 随机森林accuracy\n",
      "0.5866666666666667 随机森林recall\n",
      "0.4449238053464687 随机森林f1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.37037037, 0.46666667, 0.38961039, 0.5       , 0.475     ,\n",
       "       0.40506329, 0.49350649, 0.48351648, 0.45454545, 0.4109589 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=138,max_depth=10,\n",
    "                       min_samples_split=84,min_samples_leaf=20,class_weight={0: 1, 1: 4.1},\n",
    "                       max_features='sqrt',oob_score=True ,random_state=10)\n",
    "scores = model_selection.cross_val_score(RF, x_train_all, y_train_all, cv=10, scoring='accuracy')\n",
    "print(scores.mean(), '随机森林accuracy')\n",
    "scores = model_selection.cross_val_score(RF, x_train_all, y_train_all, cv=10, scoring='recall')\n",
    "print(scores.mean(), '随机森林recall')\n",
    "scores = model_selection.cross_val_score(RF, x_train_all, y_train_all, cv=10, scoring='f1')\n",
    "print(scores.mean(), '随机森林f1')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=138,max_depth=10,\n",
    "                       min_samples_split=84,min_samples_leaf=20,class_weight={0: 1, 1: 5},\n",
    "                       max_features='sqrt',oob_score=True ,random_state=10) \n",
    "#scores = model_selection.cross_val_score(RF, x_train_all, y_train_all, cv=10, scoring='f1')\n",
    "#print(i,scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 5},\n",
       "            criterion='gini', max_depth=10, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=20,\n",
       "            min_samples_split=84, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=138, n_jobs=None, oob_score=True, random_state=10,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,  38],\n",
       "       [ 14,  27]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585365853658537\n",
      "0.4153846153846154\n",
      "0.509433962264151\n"
     ]
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict)\n",
    "a = metrics.recall_score(y_test,y_predict)\n",
    "print(a)\n",
    "b = metrics.precision_score(y_test,y_predict)\n",
    "print(b)\n",
    "f1 = 2*a*b/(a + b)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(estimator, name='estimator'):\n",
    "    auc = cross_val_score(estimator, x_train_all,y_train_all, scoring='roc_auc', cv=3).mean()\n",
    "    precision = cross_val_score(estimator, x_train_all,y_train_all, scoring='precision', cv=3).mean()\n",
    "    f1 = cross_val_score(estimator,x_train_all,y_train_all, scoring='f1', cv=3).mean()\n",
    "    recall = cross_val_score(estimator, x_train_all,y_train_all, scoring='recall', cv=3).mean()\n",
    "\n",
    "    print('auc',auc)\n",
    "    print('precision',precision)    \n",
    "    print('recall',recall)    \n",
    "    print('f1',f1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.7674866666666667\n",
      "precision 0.35499283325370284\n",
      "recall 0.5666666666666668\n",
      "f1 0.429673125856332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "v1 = XGBClassifier( learning_rate =0.11, n_estimators=39, max_depth=4,\n",
    "                     min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,reg_alpha=1.505,\n",
    "                     objective= 'binary:logistic', nthread=4, scale_pos_weight=5,seed=27)\n",
    "\n",
    "v2 = RandomForestClassifier(n_estimators=132,max_depth=11,min_samples_split=80,min_samples_leaf=20,\n",
    "                            class_weight={0: 1, 1: 5},max_features='sqrt',oob_score=True ,random_state=10)\n",
    "\n",
    "\n",
    "estimators = []\n",
    "# estimators.append(('RidgeClassifier', RidgeClassifier()))\n",
    "estimators.append(('LogisticRegression', LogisticRegression(solver='lbfgs',class_weight='balanced')))\n",
    "estimators.append(('XGBClassifier', v1))\n",
    "estimators.append(('AdaBoostClassifier', v2))\n",
    "# estimators.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "\n",
    "#voting: auc:0.794587, recall:0.000642, accuracy:0.944433\n",
    "\n",
    "voting = VotingClassifier(estimators = estimators, voting='soft') \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(voting,n_estimators=50)\n",
    "# 计算交叉验证的准确率\n",
    "#scores = cross_val_score(bagging_clf, train_data, train_target, cv=3)\n",
    "#print(scores.mean()) \n",
    "\n",
    "\n",
    "#bagging_clf.fit(x_train,y_train)\n",
    "#y_predict = bagging_clf.predict(x_test)\n",
    "estimate(bagging_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5609756097560976\n",
      "0.40350877192982454\n",
      "0.46938775510204084\n"
     ]
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict)\n",
    "a = metrics.recall_score(y_test,y_predict)\n",
    "print(a)\n",
    "b = metrics.precision_score(y_test,y_predict)\n",
    "print(b)\n",
    "f1 = 2*a*b/(a + b)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存预测结果\n",
    "y_predict = gsearch1.predict(x_test_data)\n",
    "df = pd.DataFrame(columns=['ID','Predicted_Results'])\n",
    "df['ID'] = test_data.iloc[:,0]\n",
    "df['Predicted_Results'] = y_predict\n",
    "df.to_csv('output/result_random.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('output/result_0.5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.columns = ['ID','RS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RS</th>\n",
       "      <th>Predicted_Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43988</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3390</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  RS  Predicted_Results\n",
       "0  104191   0                0.0\n",
       "1   43988   1                1.0\n",
       "2    3390   1                1.0\n",
       "3   37343   0                0.0\n",
       "4   56827   0                0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mer = pd.merge(a,df,on = 'ID')\n",
    "mer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = mer[mer.RS != mer.Predicted_Results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
